{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "145e3859-5288-46c9-a0bf-5a8f79fb0b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef848469-efdb-41f6-9f54-830176112453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import datetime\n",
    "import shutil\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "sys.path.insert(0, '../../../SimCLRv2-PyTorch/')\n",
    "\n",
    "from utils.model import save_model, load_optimizer\n",
    "from simclr.modules import LogisticRegression\n",
    "from simclr import SimCLRv2, SimCLRv2_ft\n",
    "from simclr.modules import get_resnet, NT_Xent\n",
    "from simclr.modules.transformations import TransformsSimCLR\n",
    "from utils import yaml_config_hook\n",
    "from utils.img_dataset_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad8d6833-d76a-4bbf-8570-649373a3f817",
   "metadata": {},
   "outputs": [],
   "source": [
    "simclr_repo = Path('/home/kaipak/dev/SimCLRv2-PyTorch/')\n",
    "parser = argparse.ArgumentParser(description=\"SimCLR\")\n",
    "config = yaml_config_hook('simclrv2_config_marsv2.yaml')\n",
    "tb_out = Path('/home/kaipak/models/tensorboard_logs')\n",
    "\n",
    "for k, v in config.items():\n",
    "    parser.add_argument(f\"--{k}\", default=v, type=type(v))\n",
    "    \n",
    "args = parser.parse_args([])\n",
    "args.device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f4cd0470-73cc-489a-8140-b6951e2e8c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nodes': 1,\n",
       " 'gpus': 4,\n",
       " 'nr': 0,\n",
       " 'dataparallel': 0,\n",
       " 'workers': 32,\n",
       " 'dataset_dir': '/home/kaipak/datasets',\n",
       " 'seed': 42,\n",
       " 'batch_size': 128,\n",
       " 'image_size': 224,\n",
       " 'start_epoch': 0,\n",
       " 'epochs': 100,\n",
       " 'pretrain': True,\n",
       " 'optimizer': 'LARS',\n",
       " 'weight_decay': 1e-06,\n",
       " 'temperature': 0.5,\n",
       " 'model_path': '/home/kaipak/models/SimCLRv2/save',\n",
       " 'epoch_num': 100,\n",
       " 'reload': False}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f2d248-e72c-4212-890b-04a98840e471",
   "metadata": {},
   "source": [
    "# Data\n",
    "Data collected from Zenodo: https://zenodo.org/record/4033453"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3272fc26-c402-40ab-aaf9-8dda90437c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up some data structures we'll need\n",
    "def text2df(filename, sep=r'\\s+', names=['img', 'label'], df_desc=None, label_set=None, drop_other=False):\n",
    "  \"\"\"Get dataframes from label text\"\"\"\n",
    "  df = pd.read_csv(filename, sep=sep, header=None, names=names, index_col=None, engine='python')\n",
    "  if df_desc is not None:\n",
    "    df = pd.merge(df, df_desc, on='label', how=\"left\", sort=False)\n",
    "  if label_set is not None:\n",
    "    df['label_set'] = label_set\n",
    "    df['img'] = df['img'].str.replace('calibrated/', '')\n",
    "  if drop_other:\n",
    "    df = df.loc[~df.label_desc.isin([\"Other rover part\", \"Artifact\"])]\n",
    "  return df\n",
    "\n",
    "def sumarize(df, proportion=True):\n",
    "  \"\"\"Sumamry proportion of datasets\"\"\"\n",
    "  \n",
    "  if proportion:\n",
    "    df_sum = df.groupby(by=['label_desc']).size().to_frame(name=\"proportion\")\n",
    "    df_sum['proportion'] /= df.shape[0]\n",
    "  else:\n",
    "    df_sum = df.groupby(by=['label_desc']).size().to_frame(name=\"count\")\n",
    "  return df_sum.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a022e69f-55a7-44da-9703-c3df2177c8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = Path('/home/kaipak/datasets/msl-labeled-data-set-v2.1/')\n",
    "BASE_IMG_PATH = BASE_PATH / 'images'\n",
    "PROC_IMG_PATH = Path('/home/kaipak/datasets/msl-labeled-data-set-v2.1-processed')\n",
    "\n",
    "IMG_ALL      = Path(BASE_IMG_PATH)\n",
    "LABEL_DESC   = pd.read_csv(f'{BASE_PATH}/class_map.csv', names=['label', 'label_desc'])\n",
    "TEST_LABELS  = text2df(f'{BASE_PATH}/test-set-v2.1.txt', df_desc=LABEL_DESC, label_set=\"test\")\n",
    "TRAIN_LABELS = text2df(f'{BASE_PATH}/train-set-v2.1.txt', df_desc=LABEL_DESC, label_set=\"train\")\n",
    "VAL_LABELS   = text2df(f'{BASE_PATH}/val-set-v2.1.txt', df_desc=LABEL_DESC, label_set=\"validation\")\n",
    "ALL_LABELS   = pd.concat([TEST_LABELS, TRAIN_LABELS, VAL_LABELS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44028ce1-8e88-453a-9c2d-25bf12bf07db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>label</th>\n",
       "      <th>label_desc</th>\n",
       "      <th>label_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0042MR0001830110101823Q01_DRCL.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>Artifact</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0042MR0001830110101823Q01_DRCL-fh.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>Artifact</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0442MH0001520020200158I01_DRCL.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>Close-up rock</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0442MH0001520020200158I01_DRCL-r90.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>Close-up rock</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0442MH0001520020200158I01_DRCL-r180.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>Close-up rock</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       img  label     label_desc label_set\n",
       "0       0042MR0001830110101823Q01_DRCL.jpg      2       Artifact     train\n",
       "1    0042MR0001830110101823Q01_DRCL-fh.jpg      2       Artifact     train\n",
       "2       0442MH0001520020200158I01_DRCL.jpg      4  Close-up rock     train\n",
       "3   0442MH0001520020200158I01_DRCL-r90.jpg      4  Close-up rock     train\n",
       "4  0442MH0001520020200158I01_DRCL-r180.jpg      4  Close-up rock     train"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_LABELS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9d0a2a2-b743-492c-b3fe-4c0d953b39a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 5920\n",
      "Val dataset size: 300\n",
      "Test dataset size: 600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>label_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Arm cover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Other rover part</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Artifact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Nearby surface</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Close-up rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>DRT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>DRT spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Distant landscape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Drill hole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Night sky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Float</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Layers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Light-toned veins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Mastcam cal target</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Sand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>Wheel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Wheel joint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>Wheel tracks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label          label_desc\n",
       "0       0           Arm cover\n",
       "1       1    Other rover part\n",
       "2       2            Artifact\n",
       "3       3      Nearby surface\n",
       "4       4       Close-up rock\n",
       "5       5                 DRT\n",
       "6       6            DRT spot\n",
       "7       7   Distant landscape\n",
       "8       8          Drill hole\n",
       "9       9           Night sky\n",
       "10     10               Float\n",
       "11     11              Layers\n",
       "12     12   Light-toned veins\n",
       "13     13  Mastcam cal target\n",
       "14     14                Sand\n",
       "15     15                 Sun\n",
       "16     16               Wheel\n",
       "17     17         Wheel joint\n",
       "18     18        Wheel tracks"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Train dataset size: {TRAIN_LABELS.shape[0]}')\n",
    "print(f'Val dataset size: {VAL_LABELS.shape[0]}')\n",
    "print(f'Test dataset size: {TEST_LABELS.shape[0]}')\n",
    "LABEL_DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c04fcb17-0812-43f3-afd3-7beb32a76065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kaipak/datasets/msl-v2.1-full/train\n",
      "/home/kaipak/datasets/msl-v2.1-full/validation\n",
      "/home/kaipak/datasets/msl-v2.1-full/test\n"
     ]
    }
   ],
   "source": [
    "# MSL Dataset Generator \n",
    "BASE_DIR = Path('/home/kaipak/datasets/msl-v2.1-full')\n",
    "for dataset, df_set in {'train': TRAIN_LABELS, \n",
    "                        'validation': VAL_LABELS, \n",
    "                        'test': TEST_LABELS}.items():\n",
    "    dest_path = BASE_DIR / dataset\n",
    "    if dest_path.exists() and dest_path.is_dir():\n",
    "        shutil.rmtree(dest_path)\n",
    "    dest_path.mkdir(parents=True, exist_ok=True)\n",
    "    print(dest_path)\n",
    "    \n",
    "    # Make directories for all images\n",
    "    for label in LABEL_DESC.label_desc:\n",
    "        (dest_path / label).mkdir()\n",
    "    \n",
    "    for i, row in df_set.iterrows():\n",
    "        shutil.copy(BASE_IMG_PATH / row.img, dest_path / row.label_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0d3bde32-dc15-4fef-beb9-c32ee958288a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "\n",
    "train_images = torchvision.datasets.ImageFolder('/home/kaipak/datasets/msl-v2.1-full/train',\n",
    "                                                transform=TransformsSimCLR(size=args.image_size).test_transform)\n",
    "valid_images = torchvision.datasets.ImageFolder('/home/kaipak/datasets/msl-v2.1-full/validation',\n",
    "                                                transform=TransformsSimCLR(size=args.image_size).test_transform)\n",
    "test_images = torchvision.datasets.ImageFolder('/home/kaipak/datasets/msl-v2.1-full/test', \n",
    "                                               transform=TransformsSimCLR(size=args.image_size).test_transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_images, batch_size=bs, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_images, batch_size=bs, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_images, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9065a08c-256e-4aa1-a74f-6dabff537bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x79ffe369ca50>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57d07a50-42dd-4d5d-ad30-0c8c4c1d0d68",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f3c5703c-5c2b-4056-8347-3a97f9585b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 4 GPUs!\n"
     ]
    }
   ],
   "source": [
    "n_classes = len(train_loader.classes)\n",
    "simclr_model = SimCLRv2(resnet_depth=50, resnet_width_multiplier=2, sk_ratio=0.0625, \n",
    "                        pretrained_weights='/home/kaipak/models/SimCLRv2/r50_2x_sk1.pth')\n",
    "simclr_model_ft = SimCLRv2_ft(simclr_model, n_classes)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  simclr_model_ngpu = nn.DataParallel(simclr_model_ft)\n",
    "\n",
    "simclr_model = simclr_model_ngpu.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1ce22e94-ac71-491b-9a7f-81bc41c98330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, loader, model, criterion, optimizer, writer):\n",
    "    \"\"\"Train evaluation model\"\"\"\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    model.train()\n",
    "    \n",
    "    for step, input in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "        X, y = input\n",
    "        X = X.cuda(non_blocking=True)\n",
    "        y = y.cuda(non_blocking=True)\n",
    "        \n",
    "        output = model(X)\n",
    "        step_loss = criterion(output, y)\n",
    "        \n",
    "        predicted = output.argmax(1)\n",
    "        step_accuracy = (predicted == y).sum().item() / y.size(0)\n",
    "        epoch_accuracy += step_accuracy\n",
    "        \n",
    "        step_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += step_loss\n",
    "        writer.add_scalar(\"Accuracy/train_step\", step_accuracy, args.global_step)\n",
    "        args.global_step += 1\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            print(f\"Step [{step}/{len(loader)}]\\t Accuracy {step_accuracy}...\")\n",
    "        \n",
    "    writer.add_scalar(\"Accuracy/train_epoch\", step_accuracy, args.current_epoch)\n",
    "    writer.add_scalar(\"Loss/train_epoch\", epoch_loss, args.current_epoch)\n",
    "\n",
    "    return epoch_loss, epoch_accuracy\n",
    "\n",
    "def test(args, loader, model, criterion, optimizer):\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    model.eval()\n",
    "    \n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        model.zero_grad()\n",
    "        \n",
    "        x = x.to(args.device)\n",
    "        y = y.to(args.device)\n",
    "        \n",
    "        output = model(x)\n",
    "        step_loss = criterion(output, y)\n",
    "        \n",
    "        predicted = output.argmax(1)\n",
    "        step_accuracy = (predicted == y).sum().item() / y.size(0)\n",
    "        epoch_accuracy += step_accuracy\n",
    "        \n",
    "        epoch_loss += step_loss.item()\n",
    "    \n",
    "    return epoch_loss, epoch_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a99ca03f-abc1-46c4-975a-0954fb35dab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer, scheduler = load_optimizer(args, simclr_model)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "writer = SummaryWriter(log_dir='/home/kaipak/models/runs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "803bf97f-4417-4130-a811-0a4105478e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 µs, sys: 1 µs, total: 9 µs\n",
      "Wall time: 18.4 µs\n",
      "Step [0/93]\t Accuracy 0.0...\n",
      "Epoch [0/3]\t Loss: 1.0710080862045288\t Accuracy: 0.7054771505376344\n",
      "Step [0/93]\t Accuracy 0.890625...\n",
      "Epoch [1/3]\t Loss: 0.27717193961143494\t Accuracy: 0.913138440860215\n",
      "Step [0/93]\t Accuracy 0.953125...\n",
      "Epoch [2/3]\t Loss: 0.13093070685863495\t Accuracy: 0.9566532258064516\n",
      "[FINAL]\t Loss: 0.7342144995927811\t Accuracy: 0.8239583333333333\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "args.global_step = 0\n",
    "args.current_epoch = 0\n",
    "args.logistic_epochs = 3\n",
    "tb_writer =  SummaryWriter(log_dir=f'/home/kaipak/models/tensorboard_logs/' +\n",
    "                           f'{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}')\n",
    "\n",
    "#for epoch in range(args.logistic_epochs):\n",
    "for epoch in range(args.logistic_epochs):\n",
    "    loss_epoch, accuracy_epoch = train(args, train_loader, simclr_model, criterion, optimizer, tb_writer)\n",
    "    \n",
    "    print(f\"Epoch [{epoch}/{args.logistic_epochs}]\\t Loss: {loss_epoch / len(train_loader)}\\t Accuracy: {accuracy_epoch / len(train_loader)}\")\n",
    "    \n",
    "    args.current_epoch += 1\n",
    "\n",
    "loss_epoch, accuracy_epoch = test(\n",
    "    args, test_loader, simclr_model, criterion, optimizer\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"[FINAL]\\t Loss: {loss_epoch / len(test_loader)}\\t Accuracy: {accuracy_epoch / len(test_loader)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5024b7e-9b8e-4d54-8269-01958e753ac6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

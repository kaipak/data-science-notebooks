{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f386463-67b6-4c7f-bfd6-eabb472fb39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffbfb2c-8a78-4cb6-bcbe-0385e63e4ab9",
   "metadata": {},
   "source": [
    "## Conversion to SimCLRv2 and Converting TF Pretrained Weights\n",
    "Pretrained weights can be found on Google's [repo](https://github.com/google-research/simclr). With conversion scripts linked. Most of the inital work can be found in spijkervet_prototypes.ipynb. This work is to clean up the spaghetti code and turn into modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "166a26a8-2db6-4c3a-801e-9cea8557459e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "sys.path.insert(0, '../../../SimCLRv2-PyTorch/')\n",
    "\n",
    "from utils.model import save_model, load_optimizer\n",
    "from simclr.modules import LogisticRegression\n",
    "from simclr import SimCLRv2, SimCLRv2_ft\n",
    "from simclr.modules import get_resnet_pt, get_resnet_v2, NT_Xent\n",
    "from simclr.modules.transformations import TransformsSimCLR\n",
    "from utils import yaml_config_hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5924409-4624-47a5-8947-3222c62f8dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "simclr_repo = Path('/home/kaipak/dev/SimCLRv2-PyTorch/')\n",
    "parser = argparse.ArgumentParser(description=\"SimCLR\")\n",
    "config = yaml_config_hook(simclr_repo / 'config/config.yaml')\n",
    "tb_out = Path('/home/kaipak/models/tensorboard_logs')\n",
    "\n",
    "for k, v in config.items():\n",
    "    parser.add_argument(f\"--{k}\", default=v, type=type(v))\n",
    "    \n",
    "args = parser.parse_args([])\n",
    "args.device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43dbf396-7d6c-40d7-8a95-eb5cda64c305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64,\n",
      " 'dataparallel': 0,\n",
      " 'dataset': 'CIFAR100',\n",
      " 'dataset_dir': '/home/kaipak/datasets',\n",
      " 'device': device(type='cuda'),\n",
      " 'epoch_num': 100,\n",
      " 'epochs': 400,\n",
      " 'gpus': 4,\n",
      " 'image_size': 224,\n",
      " 'logistic_batch_size': 96,\n",
      " 'logistic_epochs': 500,\n",
      " 'model_path': '/home/kaipak/models/SimCLRv2/save',\n",
      " 'nodes': 1,\n",
      " 'nr': 0,\n",
      " 'optimizer': 'LARS',\n",
      " 'pretrain': True,\n",
      " 'projection_dim': 64,\n",
      " 'reload': False,\n",
      " 'resnet': 'resnet50',\n",
      " 'seed': 42,\n",
      " 'start_epoch': 0,\n",
      " 'temperature': 0.5,\n",
      " 'weight_decay': 1e-06,\n",
      " 'workers': 64}\n"
     ]
    }
   ],
   "source": [
    "args.batch_size = 64\n",
    "args.logistic_batch_size = 96\n",
    "args.resnet = \"resnet50\"\n",
    "args.epochs = 400\n",
    "args.gpus = 4\n",
    "args.optimizer = 'LARS'\n",
    "args.workers = 64\n",
    "args.dataset = 'CIFAR100'\n",
    "pprint(vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8876c5c5-fd92-41e6-bbec-3a57471d7517",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "if args.dataset == \"STL10\":\n",
    "    train_dataset = torchvision.datasets.STL10(\n",
    "        args.dataset_dir,\n",
    "        split=\"unlabeled\",\n",
    "        download=True,\n",
    "        transform=TransformsSimCLR(size=args.image_size),\n",
    "    )\n",
    "elif args.dataset == \"CIFAR10\":\n",
    "    train_dataset = torchvision.datasets.CIFAR10(\n",
    "        args.dataset_dir,\n",
    "        download=True,\n",
    "        transform=TransformsSimCLR(size=args.image_size),\n",
    "    )\n",
    "elif args.dataset == \"CIFAR100\":\n",
    "    train_dataset = torchvision.datasets.CIFAR100(\n",
    "        args.dataset_dir,\n",
    "        download=True,\n",
    "        transform=TransformsSimCLR(size=args.image_size),\n",
    "    )\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "if args.nodes > 1:\n",
    "    train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "        train_dataset, num_replicas=args.world_size, rank=rank, shuffle=True\n",
    "    )\n",
    "else:\n",
    "    train_sampler = None\n",
    "\n",
    "\n",
    "# Data Transforms happen here.\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=(train_sampler is None),\n",
    "    drop_last=True,\n",
    "    num_workers=args.workers,\n",
    "    sampler=train_sampler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c71d91b6-606a-4f7b-a824-0102cd7ca54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "if args.dataset == \"STL10\":\n",
    "    train_dataset = torchvision.datasets.STL10(\n",
    "        args.dataset_dir,\n",
    "        split=\"train\",\n",
    "        download=True,\n",
    "        transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "    )\n",
    "    test_dataset = torchvision.datasets.STL10(\n",
    "        args.dataset_dir,\n",
    "        split=\"test\",\n",
    "        download=True,\n",
    "        transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "    )\n",
    "elif args.dataset == \"CIFAR10\":\n",
    "    train_dataset = torchvision.datasets.CIFAR10(\n",
    "        args.dataset_dir,\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "    )\n",
    "    test_dataset = torchvision.datasets.CIFAR10(\n",
    "        args.dataset_dir,\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "    )\n",
    "elif args.dataset == \"CIFAR100\":\n",
    "    train_dataset = torchvision.datasets.CIFAR100(\n",
    "        args.dataset_dir,\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "    )\n",
    "    test_dataset = torchvision.datasets.CIFAR100(\n",
    "        args.dataset_dir,\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "    )\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=args.logistic_batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=args.workers,\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    #batch_size=args.logistic_batch_size,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    "    num_workers=args.workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3f7ffc-3f27-46d9-b2a7-a76824c5942e",
   "metadata": {},
   "source": [
    "## SimCLRv2: Self Supervised Learning\n",
    "Modified SimCLR Pytorch code to v2 with Resnet code from converter which includes contrastive head.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01870e1-d81a-461a-b2c7-1b7aa0521a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimCLRv2(resnet_depth=50, resnet_width_multiplier=2)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "  model = nn.DataParallel(model)\n",
    "\n",
    "if args.reload:\n",
    "    model_fp = os.path.join(\n",
    "        args.model_path, f\"checkpoint_{args.epoch_num}.tar\"\n",
    "    )\n",
    "    model.load_state_dict(torch.load(model_fp, map_location=args.device.type))\n",
    "\n",
    "model = model.to(args.device)\n",
    "optimizer, scheduler = load_optimizer(args, model)\n",
    "criterion = NT_Xent(args.batch_size, args.temperature, world_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa98c3cf-5a65-429a-bd5c-abc345aaa43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, train_loader, model, criterion, optimizer, writer, display_every=50):\n",
    "    \"\"\"Train function\"\"\"\n",
    "    \n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    \n",
    "    for step, ((x_i, x_j), _) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        sys.exit()\n",
    "        x_i = x_i.cuda(non_blocking=True)\n",
    "        x_j = x_j.cuda(non_blocking=True)\n",
    "        \n",
    "        # Positive pair with encoding\n",
    "        h_i, h_j, z_i, z_j = model(x_i, x_j)\n",
    "        \n",
    "        loss = criterion(z_i, z_j)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step % display_every == 0:\n",
    "            print(f\"Step [{step}/{len(train_loader)}]\\t Loss: {loss.item()}\")\n",
    "        \n",
    "        writer.add_scalar(\"Loss/train_epoch\", loss.item(), args.global_step)\n",
    "        epoch_loss += loss.item()\n",
    "        args.global_step += 1\n",
    "    \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3573bdad-e6f8-48ef-a72a-7cc0afbccc51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args.global_step = 0\n",
    "args.current_epoch = 0\n",
    "tb_writer =  SummaryWriter(log_dir=f'/home/kaipak/models/tensorboard_logs/' +\n",
    "                           f'{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}')\n",
    "\n",
    "for epoch in range(args.start_epoch, args.epochs):\n",
    "    lr = optimizer.param_groups[0][\"lr\"]\n",
    "    epoch_loss = train(args, train_loader, model, criterion, optimizer, tb_writer)\n",
    "    \n",
    "    if scheduler:\n",
    "        scheduler.step()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        save_model(args, model, optimizer)\n",
    "    \n",
    "    writer.add_scalar(\"Loss/train\", epoch_loss / len(train_loader), epoch)\n",
    "    writer.add_scalar(\"Misc/learning_rate\", lr, epoch)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch}/{args.epochs}]\\t Loss: {epoch_loss / len(train_loader)}\\t lr: {round(lr, 5)}\"\n",
    "    )\n",
    "    args.current_epoch += 1\n",
    "\n",
    "save_model(args, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8414383-2ba3-4bbb-a0ce-6987f0926130",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d29f0dc-ec7f-4096-b4e7-77b35de6e605",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.load('/home/kaipak/models/SimCLRv2/r50_2x_sk1.pth').keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3702ff22-bfb0-4e61-82b1-06cc59620405",
   "metadata": {},
   "outputs": [],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d25df3e-329c-4193-9749-3ec0e8359f6c",
   "metadata": {},
   "source": [
    "## SimCLRv2: Fine Tuning From Projection Head\n",
    "v2 says we should fine tune from middle projection layer. Original SimCLR implementation basically throws this away and additionally does not have fine-tuning step from Resnet. Build code to take middle layer of projection then run supervised fine-tuning using cross-entropy as loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abbfbfb2-f5e8-45a2-ba66-aec8fe6e2c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 4 GPUs!\n"
     ]
    }
   ],
   "source": [
    "n_classes = 100\n",
    "simclr_model = SimCLRv2(resnet_depth=50, resnet_width_multiplier=2, sk_ratio=0.0625, \n",
    "                        pretrained_weights='/home/kaipak/models/SimCLRv2/r50_2x_sk1.pth')\n",
    "simclr_model_ft = SimCLRv2_ft(simclr_model, n_classes)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  simclr_model_ngpu = nn.DataParallel(simclr_model_ft)\n",
    "\n",
    "simclr_model = simclr_model_ngpu.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8970a9d7-971b-45a3-a7fc-ea5b6bceba21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, loader, model, criterion, optimizer, writer):\n",
    "    \"\"\"Train evaluation model\"\"\"\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    model.train()\n",
    "    \n",
    "    for step, input in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "        X, y = input\n",
    "        X = X.cuda(non_blocking=True)\n",
    "        y = y.cuda(non_blocking=True)\n",
    "        \n",
    "        output = model(X)\n",
    "        step_loss = criterion(output, y)\n",
    "        \n",
    "        predicted = output.argmax(1)\n",
    "        step_accuracy = (predicted == y).sum().item() / y.size(0)\n",
    "        epoch_accuracy += step_accuracy\n",
    "        \n",
    "        step_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += step_loss\n",
    "        writer.add_scalar(\"Accuracy/train_step\", step_accuracy, args.global_step)\n",
    "        args.global_step += 1\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            print(f\"Step [{step}/{len(loader)}]\\t Accuracy {step_accuracy}...\")\n",
    "        \n",
    "    writer.add_scalar(\"Accuracy/train_epoch\", step_accuracy, args.current_epoch)\n",
    "    writer.add_scalar(\"Loss/train_epoch\", epoch_loss, args.current_epoch)\n",
    "\n",
    "    return epoch_loss, epoch_accuracy\n",
    "\n",
    "def test(args, loader, model, criterion, optimizer):\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    model.eval()\n",
    "    \n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        model.zero_grad()\n",
    "        \n",
    "        x = x.to(args.device)\n",
    "        y = y.to(args.device)\n",
    "        \n",
    "        output = model(x)\n",
    "        step_loss = criterion(output, y)\n",
    "        \n",
    "        predicted = output.argmax(1)\n",
    "        step_accuracy = (predicted == y).sum().item() / y.size(0)\n",
    "        epoch_accuracy += step_accuracy\n",
    "        \n",
    "        epoch_loss += step_loss.item()\n",
    "    \n",
    "    return epoch_loss, epoch_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecc17ad6-0385-4ec3-b1f7-e1707142f56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer, scheduler = load_optimizer(args, simclr_model)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "writer = SummaryWriter(log_dir='/home/kaipak/models/runs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1801014-f200-494b-b4ec-627600db3e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 µs, sys: 1e+03 ns, total: 7 µs\n",
      "Wall time: 14.1 µs\n",
      "Step [0/520]\t Accuracy 0.0...\n",
      "Step [100/520]\t Accuracy 0.23958333333333334...\n",
      "Step [200/520]\t Accuracy 0.5833333333333334...\n",
      "Step [300/520]\t Accuracy 0.6354166666666666...\n",
      "Step [400/520]\t Accuracy 0.6979166666666666...\n",
      "Step [500/520]\t Accuracy 0.7604166666666666...\n",
      "Epoch [0/5]\t Loss: 2.096226215362549\t Accuracy: 0.5176883012820513\n",
      "Step [0/520]\t Accuracy 0.7916666666666666...\n",
      "Step [100/520]\t Accuracy 0.7708333333333334...\n",
      "Step [200/520]\t Accuracy 0.8541666666666666...\n",
      "Step [300/520]\t Accuracy 0.8020833333333334...\n",
      "Step [400/520]\t Accuracy 0.8333333333333334...\n",
      "Step [500/520]\t Accuracy 0.8229166666666666...\n",
      "Epoch [1/5]\t Loss: 0.6005164980888367\t Accuracy: 0.8258413461538463\n",
      "Step [0/520]\t Accuracy 0.8854166666666666...\n",
      "Step [100/520]\t Accuracy 0.8645833333333334...\n",
      "Step [200/520]\t Accuracy 0.7708333333333334...\n",
      "Step [300/520]\t Accuracy 0.9166666666666666...\n",
      "Step [400/520]\t Accuracy 0.9166666666666666...\n",
      "Step [500/520]\t Accuracy 0.875...\n",
      "Epoch [2/5]\t Loss: 0.34955671429634094\t Accuracy: 0.8960336538461539\n",
      "Step [0/520]\t Accuracy 0.96875...\n",
      "Step [100/520]\t Accuracy 0.9375...\n",
      "Step [200/520]\t Accuracy 0.9375...\n",
      "Step [300/520]\t Accuracy 0.96875...\n",
      "Step [400/520]\t Accuracy 0.9270833333333334...\n",
      "Step [500/520]\t Accuracy 0.9270833333333334...\n",
      "Epoch [3/5]\t Loss: 0.20401716232299805\t Accuracy: 0.9393429487179485\n",
      "Step [0/520]\t Accuracy 0.96875...\n",
      "Step [100/520]\t Accuracy 0.96875...\n",
      "Step [200/520]\t Accuracy 0.9895833333333334...\n",
      "Step [300/520]\t Accuracy 0.96875...\n",
      "Step [400/520]\t Accuracy 0.9583333333333334...\n",
      "Step [500/520]\t Accuracy 0.9895833333333334...\n",
      "Epoch [4/5]\t Loss: 0.11906659603118896\t Accuracy: 0.9659254807692316\n",
      "[FINAL]\t Loss: 0.46986934857872814\t Accuracy: 0.8722956730769231\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "args.global_step = 0\n",
    "args.current_epoch = 0\n",
    "args.logistic_epochs = 5\n",
    "tb_writer =  SummaryWriter(log_dir=f'/home/kaipak/models/tensorboard_logs/' +\n",
    "                           f'{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}')\n",
    "\n",
    "#for epoch in range(args.logistic_epochs):\n",
    "for epoch in range(args.logistic_epochs):\n",
    "    loss_epoch, accuracy_epoch = train(args, train_loader, simclr_model, criterion, optimizer, tb_writer)\n",
    "    \n",
    "    print(f\"Epoch [{epoch}/{args.logistic_epochs}]\\t Loss: {loss_epoch / len(train_loader)}\\t Accuracy: {accuracy_epoch / len(train_loader)}\")\n",
    "    \n",
    "    args.current_epoch += 1\n",
    "\n",
    "loss_epoch, accuracy_epoch = test(\n",
    "    args, test_loader, simclr_model, criterion, optimizer\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"[FINAL]\\t Loss: {loss_epoch / len(test_loader)}\\t Accuracy: {accuracy_epoch / len(test_loader)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bc80bb-b36c-4ac1-9857-0741e5738151",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee1620d9-3049-424a-96e8-59fece309414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ContrastiveHead(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "    (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "    (4): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=4096, out_features=128, bias=False)\n",
       "    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simclr_model = SimCLRv2(resnet_depth=50, resnet_width_multiplier=2, sk_ratio=0.0625, \n",
    "                        pretrained_weights='/home/kaipak/models/SimCLRv2/r50_2x_sk1.pth')\n",
    "simclr_model.projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4c1f6c6-6acf-4e94-b875-44262b107ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LARS (\n",
       "Parameter Group 0\n",
       "    classic_momentum: True\n",
       "    eeta: 0.001\n",
       "    exclude_from_layer_adaptation: None\n",
       "    exclude_from_weight_decay: ['batch_normalization', 'bias']\n",
       "    initial_lr: 0.075\n",
       "    lr: 0.075\n",
       "    momentum: 0.9\n",
       "    use_nesterov: False\n",
       "    weight_decay: 1e-06\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77234e09-8f75-4fc8-9005-7012c5ae4231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR100\n",
       "    Number of datapoints: 50000\n",
       "    Root location: /home/kaipak/datasets\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=224, interpolation=PIL.Image.BILINEAR)\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91205f9-175d-44e8-8878-4982c94ef242",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

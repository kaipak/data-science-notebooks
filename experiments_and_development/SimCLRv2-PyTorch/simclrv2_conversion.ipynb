{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f386463-67b6-4c7f-bfd6-eabb472fb39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffbfb2c-8a78-4cb6-bcbe-0385e63e4ab9",
   "metadata": {},
   "source": [
    "## Conversion to SimCLRv2 and Converting TF Pretrained Weights\n",
    "Pretrained weights can be found on Google's [repo](https://github.com/google-research/simclr). With conversion scripts linked. Most of the inital work can be found in spijkervet_prototypes.ipynb. This work is to clean up the spaghetti code and turn into modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "166a26a8-2db6-4c3a-801e-9cea8557459e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "from model import save_model, load_optimizer\n",
    "from simclr.modules import LogisticRegression\n",
    "from simclr import SimCLR, SimCLRv2\n",
    "from simclr.modules import get_resnet_pt, get_resnet_v2, NT_Xent\n",
    "from simclr.modules.transformations import TransformsSimCLR\n",
    "from utils import yaml_config_hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5924409-4624-47a5-8947-3222c62f8dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"SimCLR\")\n",
    "config = yaml_config_hook(\"../config/config.yaml\")\n",
    "tensorboard_\n",
    "\n",
    "for k, v in config.items():\n",
    "    parser.add_argument(f\"--{k}\", default=v, type=type(v))\n",
    "    \n",
    "args = parser.parse_args([])\n",
    "args.device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43dbf396-7d6c-40d7-8a95-eb5cda64c305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32,\n",
      " 'dataparallel': 0,\n",
      " 'dataset': 'CIFAR100',\n",
      " 'dataset_dir': './datasets',\n",
      " 'device': device(type='cuda'),\n",
      " 'epoch_num': 100,\n",
      " 'epochs': 400,\n",
      " 'gpus': 4,\n",
      " 'image_size': 224,\n",
      " 'logistic_batch_size': 256,\n",
      " 'logistic_epochs': 500,\n",
      " 'model_path': 'save',\n",
      " 'nodes': 1,\n",
      " 'nr': 0,\n",
      " 'optimizer': 'LARS',\n",
      " 'pretrain': True,\n",
      " 'projection_dim': 64,\n",
      " 'reload': False,\n",
      " 'resnet': 'resnet50',\n",
      " 'seed': 42,\n",
      " 'start_epoch': 0,\n",
      " 'temperature': 0.5,\n",
      " 'weight_decay': 1e-06,\n",
      " 'workers': 64}\n"
     ]
    }
   ],
   "source": [
    "args.batch_size = 32\n",
    "args.resnet = \"resnet50\"\n",
    "args.epochs = 400\n",
    "args.gpus = 4\n",
    "args.optimizer = 'LARS'\n",
    "args.workers = 64\n",
    "args.dataset = 'CIFAR100'\n",
    "pprint(vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8876c5c5-fd92-41e6-bbec-3a57471d7517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "if args.dataset == \"STL10\":\n",
    "    train_dataset = torchvision.datasets.STL10(\n",
    "        args.dataset_dir,\n",
    "        split=\"unlabeled\",\n",
    "        download=True,\n",
    "        transform=TransformsSimCLR(size=args.image_size),\n",
    "    )\n",
    "elif args.dataset == \"CIFAR10\":\n",
    "    train_dataset = torchvision.datasets.CIFAR10(\n",
    "        args.dataset_dir,\n",
    "        download=True,\n",
    "        transform=TransformsSimCLR(size=args.image_size),\n",
    "    )\n",
    "elif args.dataset == \"CIFAR100\":\n",
    "    train_dataset = torchvision.datasets.CIFAR100(\n",
    "        args.dataset_dir,\n",
    "        download=True,\n",
    "        transform=TransformsSimCLR(size=args.image_size),\n",
    "    )\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "if args.nodes > 1:\n",
    "    train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "        train_dataset, num_replicas=args.world_size, rank=rank, shuffle=True\n",
    "    )\n",
    "else:\n",
    "    train_sampler = None\n",
    "\n",
    "\n",
    "# Data Transforms happen here.\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=(train_sampler is None),\n",
    "    drop_last=True,\n",
    "    num_workers=args.workers,\n",
    "    sampler=train_sampler,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3f7ffc-3f27-46d9-b2a7-a76824c5942e",
   "metadata": {},
   "source": [
    "## SimCLRv2: Self Supervised Learning\n",
    "Modified SimCLR Pytorch code to v2 with Resnet code from converter which includes contrastive head.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01870e1-d81a-461a-b2c7-1b7aa0521a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimCLRv2(resnet_depth=50, resnet_width_multiplier=2)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "  model = nn.DataParallel(model)\n",
    "\n",
    "if args.reload:\n",
    "    model_fp = os.path.join(\n",
    "        args.model_path, f\"checkpoint_{args.epoch_num}.tar\"\n",
    "    )\n",
    "    model.load_state_dict(torch.load(model_fp, map_location=args.device.type))\n",
    "\n",
    "model = model.to(args.device)\n",
    "optimizer, scheduler = load_optimizer(args, model)\n",
    "criterion = NT_Xent(args.batch_size, args.temperature, world_size=1)\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa98c3cf-5a65-429a-bd5c-abc345aaa43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, train_loader, model, criterion, optimizer, writer, display_every=50):\n",
    "    \"\"\"Train function\"\"\"\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for step, ((x_i, x_j), _) in enumerate(train_loader):\n",
    "    #for step, x_i, x_j in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x_i = x_i.cuda(non_blocking=True)\n",
    "        x_j = x_j.cuda(non_blocking=True)\n",
    "        \n",
    "        # Positive pair with encoding\n",
    "        h_i, h_j, z_i, z_j = model(x_i, x_j)\n",
    "        \n",
    "        loss = criterion(z_i, z_j)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step % display_every == 0:\n",
    "            print(f\"Step [{step}/{len(train_loader)}]\\t Loss: {loss.item()}\")\n",
    "        \n",
    "        writer.add_scalar(\"Loss/train_epoch\", loss.item(), args.global_step)\n",
    "        epoch_loss += loss.item()\n",
    "        args.global_step += 1\n",
    "    \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3573bdad-e6f8-48ef-a72a-7cc0afbccc51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args.global_step = 0\n",
    "args.current_epoch = 0\n",
    "\n",
    "for epoch in range(args.start_epoch, args.epochs):\n",
    "    lr = optimizer.param_groups[0][\"lr\"]\n",
    "    epoch_loss = train(args, train_loader, model, criterion, optimizer, writer)\n",
    "    \n",
    "    if scheduler:\n",
    "        scheduler.step()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        save_model(args, model, optimizer)\n",
    "    \n",
    "    writer.add_scalar(\"Loss/train\", epoch_loss / len(train_loader), epoch)\n",
    "    writer.add_scalar(\"Misc/learning_rate\", lr, epoch)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch}/{args.epochs}]\\t Loss: {epoch_loss / len(train_loader)}\\t lr: {round(lr, 5)}\"\n",
    "    )\n",
    "    args.current_epoch += 1\n",
    "\n",
    "save_model(args, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8414383-2ba3-4bbb-a0ce-6987f0926130",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d25df3e-329c-4193-9749-3ec0e8359f6c",
   "metadata": {},
   "source": [
    "## SimCLRv2: Fine Tuning From Projection Head\n",
    "v2 paper states that fine tuning should happen from 2nd linear projection layer. Original SimCLR implementation basically throws this away and additionally does not have fine-tuning step from Resnet. Build code to take middle layer of projection then run supervised fine-tuning using cross-entropy as loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abbfbfb2-f5e8-45a2-ba66-aec8fe6e2c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 4 GPUs!\n"
     ]
    }
   ],
   "source": [
    "simclr_model = SimCLRv2(resnet_depth=50, resnet_width_multiplier=2, sk_ratio=0.0625, \n",
    "                        pretrained_weights='/home/kaipak/models/SimCLRv2/r50_2x_sk1.pth')\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "  simclr_model_ngpu = nn.DataParallel(simclr_model)\n",
    "  # simclr_model_ngpu.n_features = n_features\n",
    "\n",
    "simclr_model = simclr_model_ngpu.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a82d5190-bcde-4471-8ecc-03eca5ffc72d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper functions to map all input data X to their latent representations \n",
    "# h that are used in linear evaluation (they only have to be computed once)\n",
    "# Should be part of the processing step before FT.\n",
    "def inference(loader, simclr_model, device):\n",
    "    feature_vector = []\n",
    "    labels_vector = []\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        x = x.to(device)\n",
    "\n",
    "        # get encoding\n",
    "        with torch.no_grad():\n",
    "            h, _, z, _ = simclr_model(x, x)\n",
    "\n",
    "        h = h.detach()\n",
    "\n",
    "        feature_vector.extend(h.cpu().detach().numpy())\n",
    "        labels_vector.extend(y.numpy())\n",
    "\n",
    "        if step % 20 == 0:\n",
    "            print(f\"Step [{step}/{len(loader)}]\\t Computing features...\")\n",
    "\n",
    "    feature_vector = np.array(feature_vector)\n",
    "    labels_vector = np.array(labels_vector)\n",
    "    print(\"Features shape {}\".format(feature_vector.shape))\n",
    "    return feature_vector, labels_vector\n",
    "\n",
    "\n",
    "def get_features(context_model, train_loader, test_loader, device):\n",
    "    train_X, train_y = inference(train_loader, context_model, device)\n",
    "    test_X, test_y = inference(test_loader, context_model, device)\n",
    "    return train_X, train_y, test_X, test_y\n",
    "\n",
    "\n",
    "def create_data_loaders_from_arrays(X_train, y_train, X_test, y_test, batch_size):\n",
    "    train = torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(X_train), torch.from_numpy(y_train)\n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "\n",
    "    test = torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(X_test), torch.from_numpy(y_test)\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acabdabf-a637-4283-833e-cd8e894917eb",
   "metadata": {},
   "source": [
    "## Train/Test Split\n",
    "For linear evaluation or fine tuning, since we are now interested in labeling instead of self supervised contrastive learning, we will need to split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7817fc03-97b0-4e0f-874f-4054d331c8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "if args.dataset == \"STL10\":\n",
    "    train_dataset = torchvision.datasets.STL10(\n",
    "        args.dataset_dir,\n",
    "        split=\"train\",\n",
    "        download=True,\n",
    "        transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "    )\n",
    "    test_dataset = torchvision.datasets.STL10(\n",
    "        args.dataset_dir,\n",
    "        split=\"test\",\n",
    "        download=True,\n",
    "        transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "    )\n",
    "elif args.dataset == \"CIFAR10\":\n",
    "    train_dataset = torchvision.datasets.CIFAR10(\n",
    "        args.dataset_dir,\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "    )\n",
    "    test_dataset = torchvision.datasets.CIFAR10(\n",
    "        args.dataset_dir,\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "    )\n",
    "elif args.dataset == \"CIFAR100\":\n",
    "    train_dataset = torchvision.datasets.CIFAR100(\n",
    "        args.dataset_dir,\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "    )\n",
    "    test_dataset = torchvision.datasets.CIFAR100(\n",
    "        args.dataset_dir,\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "    )\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=args.logistic_batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=args.workers,\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=args.logistic_batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    "    num_workers=args.workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64d677d3-e1cb-4c67-8cbc-a725f50c9136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [0/195]\t Computing features...\n",
      "Step [20/195]\t Computing features...\n",
      "Step [40/195]\t Computing features...\n",
      "Step [60/195]\t Computing features...\n",
      "Step [80/195]\t Computing features...\n",
      "Step [100/195]\t Computing features...\n",
      "Step [120/195]\t Computing features...\n",
      "Step [140/195]\t Computing features...\n",
      "Step [160/195]\t Computing features...\n",
      "Step [180/195]\t Computing features...\n",
      "Features shape (49920, 4096)\n",
      "Step [0/39]\t Computing features...\n",
      "Step [20/39]\t Computing features...\n",
      "Features shape (9984, 4096)\n"
     ]
    }
   ],
   "source": [
    "(train_X, train_y, test_X, test_y) = get_features(\n",
    "    simclr_model, train_loader, test_loader, args.device\n",
    ")\n",
    "\n",
    "arr_train_loader, arr_test_loader = create_data_loaders_from_arrays(\n",
    "    train_X, train_y, test_X, test_y, args.logistic_batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab6d50c-be46-4d36-b2e8-1381e95aeb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tuning\n",
    "def train(args, train_loader, model, criterion, optimizer, writer, display_every=50):\n",
    "    \"\"\"Train function\"\"\"\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for step, ((x_i, x_j), _) in enumerate(train_loader):\n",
    "    #for step, x_i, x_j in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x_i = x_i.cuda(non_blocking=True)\n",
    "        x_j = x_j.cuda(non_blocking=True)\n",
    "        \n",
    "        # Positive pair with encoding\n",
    "        h_i, h_j, z_i, z_j = model(x_i, x_j)\n",
    "        \n",
    "        loss = criterion(z_i, z_j)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step % display_every == 0:\n",
    "            print(f\"Step [{step}/{len(train_loader)}]\\t Loss: {loss.item()}\")\n",
    "        \n",
    "        writer.add_scalar(\"Loss/train_epoch\", loss.item(), args.global_step)\n",
    "        epoch_loss += loss.item()\n",
    "        args.global_step += 1\n",
    "    \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383208d1-0a1a-497f-a463-428db8df3fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine Tune training\n",
    "def train(args, loader, simclr_model, model, criterion, optimizer, writer):\n",
    "    \"\"\"Train evaluation model\"\"\"\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    model.eval()\n",
    "    \n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        x = x.to(args.device)\n",
    "        y = y.to(args.device)\n",
    "        \n",
    "        output = model(x)\n",
    "        step_loss = criterion(output, y)\n",
    "        \n",
    "        predicted = output.argmax(1)\n",
    "        step_accuracy = (predicted == y).sum().item() / y.size(0)\n",
    "        epoch_accuracy += step_accuracy\n",
    "        \n",
    "        step_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += step_loss\n",
    "        writer.add_scalar(\"Accuracy/train_step\", step_accuracy, args.global_step)\n",
    "        args.global_step += 1\n",
    "        \n",
    "    writer.add_scalar(\"Accuracy/train_epoch\", step_accuracy, args.current_epoch)\n",
    "    writer.add_scalar(\"Loss/train_epoch\", epoch_loss, args.current_epoch)\n",
    "\n",
    "    return epoch_loss, epoch_accuracy\n",
    "\n",
    "def test(args, loader, simclr_model, model, criterion, optimizer):\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    model.eval()\n",
    "    \n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        model.zero_grad()\n",
    "        \n",
    "        x = x.to(args.device)\n",
    "        y = y.to(args.device)\n",
    "        \n",
    "        output = model(x)\n",
    "        step_loss = criterion(output, y)\n",
    "        \n",
    "        predicted = output.argmax(1)\n",
    "        step_accuracy = (predicted == y).sum().item() / y.size(0)\n",
    "        epoch_accuracy += step_accuracy\n",
    "        \n",
    "        epoch_loss += step_loss.item()\n",
    "    \n",
    "    return epoch_loss, epoch_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c8b967-4b31-4a43-b776-f8e4279e5933",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 100\n",
    "model = LogisticRegression(simclr_model.n_features, n_classes)\n",
    "if torch.cuda.device_count() > 1:\n",
    "  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "  model = nn.DataParallel(model)\n",
    "model = model.to(args.device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "#optimizer = LARS(model.parameters(), lr=3e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "writer = SummaryWriter(log_dir='/home/kaipak/models/runs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c447c43-3431-4ed6-9398-0f543cf6d845",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): SimCLRv2(\n",
       "    (encoder): ResNet(\n",
       "      (net): Sequential(\n",
       "        (0): Stem(\n",
       "          (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (1): BatchNormRelu(\n",
       "            (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU()\n",
       "          )\n",
       "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (3): BatchNormRelu(\n",
       "            (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU()\n",
       "          )\n",
       "          (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (5): BatchNormRelu(\n",
       "            (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU()\n",
       "          )\n",
       "          (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (1): Blocks(\n",
       "          (blocks): ModuleList(\n",
       "            (0): BottleneckBlock(\n",
       "              (projection): Projection(\n",
       "                (shortcut): Sequential(\n",
       "                  (0): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "                  (1): AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
       "                  (2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                )\n",
       "                (bn): BatchNormRelu(\n",
       "                  (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (1): Identity()\n",
       "                )\n",
       "              )\n",
       "              (net): Sequential(\n",
       "                (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNormRelu(\n",
       "                  (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (1): ReLU()\n",
       "                )\n",
       "                (2): SelectiveKernel(\n",
       "                  (main_conv): Sequential(\n",
       "                    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                    (1): BatchNormRelu(\n",
       "                      (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (1): ReLU()\n",
       "                    )\n",
       "                  )\n",
       "                  (mixing_conv): Sequential(\n",
       "                    (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (1): BatchNormRelu(\n",
       "                      (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (1): ReLU()\n",
       "                    )\n",
       "                    (2): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  )\n",
       "                )\n",
       "                (3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (4): BatchNormRelu(\n",
       "                  (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (1): Identity()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): BottleneckBlock(\n",
       "              (projection): Identity()\n",
       "              (net): Sequential(\n",
       "                (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNormRelu(\n",
       "                  (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (1): ReLU()\n",
       "                )\n",
       "                (2): SelectiveKernel(\n",
       "                  (main_conv): Sequential(\n",
       "                    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                    (1): BatchNormRelu(\n",
       "                      (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (1): ReLU()\n",
       "                    )\n",
       "                  )\n",
       "                  (mixing_conv): Sequential(\n",
       "                    (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (1): BatchNormRelu(\n",
       "                      (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (1): ReLU()\n",
       "                    )\n",
       "                    (2): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  )\n",
       "                )\n",
       "                (3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (4): BatchNormRelu(\n",
       "                  (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (1): Identity()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): BottleneckBlock(\n",
       "              (projection): Identity()\n",
       "              (net): Sequential(\n",
       "                (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNormRelu(\n",
       "                  (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (1): ReLU()\n",
       "                )\n",
       "                (2): SelectiveKernel(\n",
       "                  (main_conv): Sequential(\n",
       "                    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                    (1): BatchNormRelu(\n",
       "                      (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (1): ReLU()\n",
       "                    )\n",
       "                  )\n",
       "                  (mixing_conv): Sequential(\n",
       "                    (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (1): BatchNormRelu(\n",
       "                      (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (1): ReLU()\n",
       "                    )\n",
       "                    (2): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  )\n",
       "                )\n",
       "                (3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (4): BatchNormRelu(\n",
       "                  (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (1): Identity()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): Blocks(\n",
       "          (blocks): ModuleList(\n",
       "            (0): BottleneckBlock(\n",
       "              (projection): Projection(\n",
       "                (shortcut): Sequential(\n",
       "                  (0): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "                  (1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "                  (2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                )\n",
       "                (bn): BatchNormRelu(\n",
       "                  (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (1): Identity()\n",
       "                )\n",
       "              )\n",
       "              (net): Sequential(\n",
       "                (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNormRelu(\n",
       "                  (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (1): ReLU()\n",
       "                )\n",
       "                (2): SelectiveKernel(\n",
       "                  (main_conv): Sequential(\n",
       "                    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                    (1): BatchNormRelu(\n",
       "                      (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (1): ReLU()\n",
       "                    )\n",
       "                  )\n",
       "                  (mixing_conv): Sequential(\n",
       "                    (0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (1): BatchNormRelu(\n",
       "                      (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (1): ReLU()\n",
       "                    )\n",
       "                    (2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  )\n",
       "                )\n",
       "                (3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (4): BatchNormRelu(\n",
       "                  (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (1): Identity()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): BottleneckBlock(\n",
       "              (projection): Identity()\n",
       "              (net): Sequential(\n",
       "                (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNormRelu(\n",
       "                  (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (1): ReLU()\n",
       "                )\n",
       "                (2): SelectiveKernel(\n",
       "                  (main_conv): Sequential(\n",
       "                    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                    (1): BatchNormRelu(\n",
       "                      (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (1): ReLU()\n",
       "                    )\n",
       "                  )\n",
       "                  (mixing_conv): Sequential(\n",
       "                    (0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (1): BatchNormRelu(\n",
       "                      (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (1): ReLU()\n",
       "                    )\n",
       "                    (2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  )\n",
       "                )\n",
       "                (3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (4): BatchNormRelu(\n",
       "                  (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (1): Identity()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): BottleneckBlock(\n",
       "              (projection): Identity()\n",
       "              (net): Sequential(\n",
       "                (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNormRelu(\n",
       "                  (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (1): ReLU()\n",
       "                )\n",
       "                (2): SelectiveKernel(\n",
       "                  (main_conv): Sequential(\n",
       "                    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                    (1): BatchNormRelu(\n",
       "                      (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (1): ReLU()\n",
       "                    )\n",
       "                  )\n",
       "                  (mixing_conv): Sequential(\n",
       "                    (0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (1): BatchNormRelu(\n",
       "                      (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (1): ReLU()\n",
       "                    )\n",
       "                    (2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  )\n",
       "                )\n",
       "                (3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (4): BatchNormRelu(\n",
       "                  (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (1): Identity()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): BottleneckBlock(\n",
       "              (projection): Identity()\n",
       "              (net): Sequential(\n",
       "                (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNormRelu(\n",
       "                  (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (1): ReLU()\n",
       "                )\n",
       "                (2): SelectiveKernel(\n",
       "                  (main_conv): Sequential(\n",
       "                    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                    (1): BatchNormRelu(\n",
       "                      (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (1): ReLU()\n",
       "                    )\n",
       "                  )\n",
       "                  (mixing_conv): Sequential(\n",
       "                    (0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (1): BatchNormRelu(\n",
       "                      (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (1): ReLU()\n",
       "                    )\n",
       "                    (2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  )\n",
       "                )\n",
       "                (3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (4): BatchNormRelu(\n",
       "                  (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (1): Identity()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): Blocks(\n",
       "          (blocks): ModuleList(\n",
       "            (0): BottleneckBlock(\n",
       "              (projection): Projection(\n",
       "                (shortcut): Sequential(\n",
       "                  (0): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "                  (1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "                  (2): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                )\n",
       "                (bn): BatchNormRelu(\n",
       "                  (0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (1): Identity()\n",
       "                )\n",
       "              )\n",
       "              (net): Sequential(\n",
       "                (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNormRelu(\n",
       "                  (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (1): ReLU()\n",
       "                )\n",
       "                (2): SelectiveKernel(\n",
       "                  (main_conv): Sequential(\n",
       "                    (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                    (1): BatchNormRelu(\n",
       "                      (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (1): ReLU()\n",
       "                    )\n",
       "                  )\n",
       "                  (mixing_conv): Sequential(\n",
       "                    (0): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (1): BatchNormRelu(\n",
       "                      (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (1): ReLU()\n",
       "                    )\n",
       "                    (2): Conv2d(32, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  )\n",
       "                )\n",
       "                (3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (4): BatchNormRelu(\n",
       "                  (0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (1): Identity()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): BottleneckBlock(\n",
       "              (projection): Identity()\n",
       "              (net): Sequential(\n",
       "                (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNormRelu(\n",
       "                  (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (1): ReLU()\n",
       "                )\n",
       "                (2): SelectiveKernel(\n",
       "                  (main_conv): Sequential(\n",
       "                    (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                    (1): BatchNormRelu(\n",
       "                      (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (1): ReLU()\n",
       "                    )\n",
       "                  )\n",
       "                  (mixing_conv): Sequential(\n",
       "                    (0): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (1): BatchNormRelu(\n",
       "                      (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (1): ReLU()\n",
       "                    )\n",
       "                    (2): Conv2d(32, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  )\n",
       "                )\n",
       "                (3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (4): BatchNormRelu(\n",
       "                  (0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (1): Identity()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): BottleneckBlock(\n",
       "              (projection): Identity()\n",
       "              (net): Sequential(\n",
       "                (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNormRelu(\n",
       "                  (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (1): ReLU()\n",
       "                )\n",
       "                (2): SelectiveKernel(\n",
       "                  (main_conv): Sequential(\n",
       "                    (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                    (1): BatchNormRelu(\n",
       "                      (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (1): ReLU()\n",
       "                    )\n",
       "                  )\n",
       "                  (mixing_conv): Sequential(\n",
       "                    (0): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (1): BatchNormRelu(\n",
       "                      (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (1): ReLU()\n",
       "                    )\n",
       "                    (2): Conv2d(32, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  )\n",
       "                )\n",
       "                (3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (4): BatchNormRelu(\n",
       "                  (0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (1): Identity()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): BottleneckBlock(\n",
       "              (projection): Identity()\n",
       "              (net): Sequential(\n",
       "                (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNormRelu(\n",
       "                  (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (1): ReLU()\n",
       "                )\n",
       "                (2): SelectiveKernel(\n",
       "                  (main_conv): Sequential(\n",
       "                    (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                    (1): BatchNormRelu(\n",
       "                      (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (1): ReLU()\n",
       "                    )\n",
       "                  )\n",
       "                  (mixing_conv): Sequential(\n",
       "                    (0): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (1): BatchNormRelu(\n",
       "                      (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (1): ReLU()\n",
       "                    )\n",
       "                    (2): Conv2d(32, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  )\n",
       "                )\n",
       "                (3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (4): BatchNormRelu(\n",
       "                  (0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (1): Identity()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (4): BottleneckBlock(\n",
       "              (projection): Identity()\n",
       "              (net): Sequential(\n",
       "                (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNormRelu(\n",
       "                  (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (1): ReLU()\n",
       "                )\n",
       "                (2): SelectiveKernel(\n",
       "                  (main_conv): Sequential(\n",
       "                    (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                    (1): BatchNormRelu(\n",
       "                      (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (1): ReLU()\n",
       "                    )\n",
       "                  )\n",
       "                  (mixing_conv): Sequential(\n",
       "                    (0): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (1): BatchNormRelu(\n",
       "                      (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (1): ReLU()\n",
       "                    )\n",
       "                    (2): Conv2d(32, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  )\n",
       "                )\n",
       "                (3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (4): BatchNormRelu(\n",
       "                  (0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (1): Identity()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (5): BottleneckBlock(\n",
       "              (projection): Identity()\n",
       "              (net): Sequential(\n",
       "                (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNormRelu(\n",
       "                  (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (1): ReLU()\n",
       "                )\n",
       "                (2): SelectiveKernel(\n",
       "                  (main_conv): Sequential(\n",
       "                    (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                    (1): BatchNormRelu(\n",
       "                      (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (1): ReLU()\n",
       "                    )\n",
       "                  )\n",
       "                  (mixing_conv): Sequential(\n",
       "                    (0): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (1): BatchNormRelu(\n",
       "                      (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (1): ReLU()\n",
       "                    )\n",
       "                    (2): Conv2d(32, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  )\n",
       "                )\n",
       "                (3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (4): BatchNormRelu(\n",
       "                  (0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (1): Identity()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): Blocks(\n",
       "          (blocks): ModuleList(\n",
       "            (0): BottleneckBlock(\n",
       "              (projection): Projection(\n",
       "                (shortcut): Sequential(\n",
       "                  (0): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "                  (1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "                  (2): Conv2d(2048, 4096, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                )\n",
       "                (bn): BatchNormRelu(\n",
       "                  (0): BatchNorm2d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (1): Identity()\n",
       "                )\n",
       "              )\n",
       "              (net): Sequential(\n",
       "                (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNormRelu(\n",
       "                  (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (1): ReLU()\n",
       "                )\n",
       "                (2): SelectiveKernel(\n",
       "                  (main_conv): Sequential(\n",
       "                    (0): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                    (1): BatchNormRelu(\n",
       "                      (0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (1): ReLU()\n",
       "                    )\n",
       "                  )\n",
       "                  (mixing_conv): Sequential(\n",
       "                    (0): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (1): BatchNormRelu(\n",
       "                      (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (1): ReLU()\n",
       "                    )\n",
       "                    (2): Conv2d(64, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  )\n",
       "                )\n",
       "                (3): Conv2d(1024, 4096, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (4): BatchNormRelu(\n",
       "                  (0): BatchNorm2d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (1): Identity()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): BottleneckBlock(\n",
       "              (projection): Identity()\n",
       "              (net): Sequential(\n",
       "                (0): Conv2d(4096, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNormRelu(\n",
       "                  (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (1): ReLU()\n",
       "                )\n",
       "                (2): SelectiveKernel(\n",
       "                  (main_conv): Sequential(\n",
       "                    (0): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                    (1): BatchNormRelu(\n",
       "                      (0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (1): ReLU()\n",
       "                    )\n",
       "                  )\n",
       "                  (mixing_conv): Sequential(\n",
       "                    (0): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (1): BatchNormRelu(\n",
       "                      (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (1): ReLU()\n",
       "                    )\n",
       "                    (2): Conv2d(64, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  )\n",
       "                )\n",
       "                (3): Conv2d(1024, 4096, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (4): BatchNormRelu(\n",
       "                  (0): BatchNorm2d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (1): Identity()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): BottleneckBlock(\n",
       "              (projection): Identity()\n",
       "              (net): Sequential(\n",
       "                (0): Conv2d(4096, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNormRelu(\n",
       "                  (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (1): ReLU()\n",
       "                )\n",
       "                (2): SelectiveKernel(\n",
       "                  (main_conv): Sequential(\n",
       "                    (0): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                    (1): BatchNormRelu(\n",
       "                      (0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (1): ReLU()\n",
       "                    )\n",
       "                  )\n",
       "                  (mixing_conv): Sequential(\n",
       "                    (0): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (1): BatchNormRelu(\n",
       "                      (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (1): ReLU()\n",
       "                    )\n",
       "                    (2): Conv2d(64, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  )\n",
       "                )\n",
       "                (3): Conv2d(1024, 4096, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (4): BatchNormRelu(\n",
       "                  (0): BatchNorm2d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (1): Identity()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (fc): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "    )\n",
       "    (projector): ContrastiveHead(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (4): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "        (6): Linear(in_features=4096, out_features=128, bias=False)\n",
       "        (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simclr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e22d35-d44d-4a9c-811c-4763b65ce86a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
